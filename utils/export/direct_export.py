#!/usr/bin/env python
"""
Direct checkpoint exporter for Matrix3D models with normal support

This module provides functions to export Matrix3D models to Gaussian Splat format
directly from checkpoints, avoiding the need for YAML config parsing.
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from collections import OrderedDict
from typing import Optional, Tuple, Union, Dict, Any

try:
    from nerfstudio.data.scene_box import OrientedBox
    from nerfstudio.utils.rich_utils import CONSOLE
    HAS_NERFSTUDIO = True
except ImportError:
    HAS_NERFSTUDIO = False
    # Simple fallback console
    class ConsoleFallback:
        def print(self, msg, **kwargs):
            print(msg)
    CONSOLE = ConsoleFallback()


def calculate_normals(means: torch.Tensor, quats: torch.Tensor) -> torch.Tensor:
    """
    Calculate normals from gaussian orientations using quaternions.
    By default, we assume the canonical direction is (0, 0, 1) and rotate it using the quaternion.

    Args:
        means: Gaussian centers (N, 3)
        quats: Gaussian quaternions (N, 4)

    Returns:
        normals: Calculated normals (N, 3)
    """
    # Normalize quaternions
    quats_normalized = quats / torch.norm(quats, dim=1, keepdim=True)

    # Canonical direction (pointing along positive z-axis)
    canonical_dir = torch.tensor([0.0, 0.0, 1.0], device=quats.device).expand(quats.shape[0], 3)

    # Convert quaternion to rotation matrix and apply to canonical direction
    # Quaternion to rotation matrix conversion
    qx, qy, qz, qw = quats_normalized[:, 0], quats_normalized[:, 1], quats_normalized[:, 2], quats_normalized[:, 3]

    # Compute rotation matrix from quaternion
    rot_matrix = torch.zeros((quats.shape[0], 3, 3), device=quats.device)

    # First row
    rot_matrix[:, 0, 0] = 1 - 2 * (qy**2 + qz**2)
    rot_matrix[:, 0, 1] = 2 * (qx * qy - qw * qz)
    rot_matrix[:, 0, 2] = 2 * (qx * qz + qw * qy)

    # Second row
    rot_matrix[:, 1, 0] = 2 * (qx * qy + qw * qz)
    rot_matrix[:, 1, 1] = 1 - 2 * (qx**2 + qz**2)
    rot_matrix[:, 1, 2] = 2 * (qy * qz - qw * qx)

    # Third row
    rot_matrix[:, 2, 0] = 2 * (qx * qz - qw * qy)
    rot_matrix[:, 2, 1] = 2 * (qy * qz + qw * qx)
    rot_matrix[:, 2, 2] = 1 - 2 * (qx**2 + qy**2)

    # Apply rotation to canonical direction
    normals = torch.bmm(rot_matrix, canonical_dir.unsqueeze(2)).squeeze(2)

    return normals


def write_ply(
    filename: str,
    count: int,
    map_to_tensors: OrderedDict[str, np.ndarray],
):
    """
    Writes a PLY file with given vertex properties and a tensor of float or uint8 values in the order specified by the OrderedDict.
    Note: All float values will be converted to float32 for writing.

    Parameters:
    filename (str): The name of the file to write.
    count (int): The number of vertices to write.
    map_to_tensors (OrderedDict[str, np.ndarray]): An ordered dictionary mapping property names to numpy arrays of float or uint8 values.
        Each array should be 1-dimensional and of equal length matching 'count'. Arrays should not be empty.
    """
    # Ensure count matches the length of all tensors
    if not all(tensor.size == count for tensor in map_to_tensors.values()):
        raise ValueError("Count does not match the length of all tensors")

    # Type check for numpy arrays of type float or uint8 and non-empty
    if not all(
        isinstance(tensor, np.ndarray)
        and (tensor.dtype.kind == "f" or tensor.dtype == np.uint8)
        and tensor.size > 0
        for tensor in map_to_tensors.values()
    ):
        raise ValueError("All tensors must be numpy arrays of float or uint8 type and not empty")

    with open(filename, "wb") as ply_file:
        # Write PLY header
        ply_file.write(b"ply\n")
        ply_file.write(b"format binary_little_endian 1.0\n")
        ply_file.write(b"comment Generated by Matrix3D-DirectExporter\n")
        ply_file.write(b"comment Vertical Axis: z\n")
        ply_file.write(f"element vertex {count}\n".encode())

        # Write properties, in order due to OrderedDict
        for key, tensor in map_to_tensors.items():
            data_type = "float" if tensor.dtype.kind == "f" else "uchar"
            ply_file.write(f"property {data_type} {key}\n".encode())

        ply_file.write(b"end_header\n")

        # Write binary data
        for i in range(count):
            for tensor in map_to_tensors.values():
                value = tensor[i]
                if tensor.dtype.kind == "f":
                    ply_file.write(np.float32(value).tobytes())
                elif tensor.dtype == np.uint8:
                    ply_file.write(value.tobytes())


def export_matrix3d_checkpoint(
    checkpoint_path: Union[str, Path],
    output_dir: Union[str, Path],
    output_filename: str = "splat.ply",
    obb_center: Optional[Tuple[float, float, float]] = None,
    obb_rotation: Optional[Tuple[float, float, float]] = None,
    obb_scale: Optional[Tuple[float, float, float]] = None,
    ply_color_mode: str = "sh_coeffs",
    normal_method: str = "calculate",
    device: str = "cuda:0" if torch.cuda.is_available() else "cpu",
):
    """
    Export Matrix3D model directly from checkpoint with normal support

    Args:
        checkpoint_path: Path to the model checkpoint
        output_dir: Output directory
        output_filename: Output filename
        obb_center: Center of the oriented bounding box
        obb_rotation: Rotation of the oriented bounding box (Euler angles in radians)
        obb_scale: Scale of the oriented bounding box
        ply_color_mode: Color mode ("sh_coeffs" or "rgb")
        normal_method: Method to generate normals ("calculate", "zero", or "model")
        device: Device to load the model on

    Returns:
        Path to the exported file
    """
    output_dir = Path(output_dir)
    if not output_dir.exists():
        output_dir.mkdir(parents=True)

    checkpoint_path = Path(checkpoint_path)
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpoint not found at {checkpoint_path}")

    CONSOLE.print(f"Loading checkpoint from {checkpoint_path}")

    # Load checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model_state = checkpoint.get("model", checkpoint)  # Some checkpoints store model under 'model' key

    # Extract required parameters
    map_to_tensors = OrderedDict()

    try:
        # Extract positions (means)
        if "means" in model_state:
            positions = model_state["means"].cpu().numpy()
        elif "gaussian_params.means" in model_state:
            positions = model_state["gaussian_params.means"].cpu().numpy()
        else:
            raise KeyError("Could not find gaussian positions in checkpoint")

        count = positions.shape[0]
        n = count
        map_to_tensors["x"] = positions[:, 0]
        map_to_tensors["y"] = positions[:, 1]
        map_to_tensors["z"] = positions[:, 2]

        # Extract quaternions
        if "quats" in model_state:
            quats = model_state["quats"]
        elif "gaussian_params.quats" in model_state:
            quats = model_state["gaussian_params.quats"]
        else:
            raise KeyError("Could not find quaternions in checkpoint")

        # Generate normals based on specified method
        if normal_method == "calculate":
            CONSOLE.print("Calculating normals from Gaussian orientations...")
            normals = calculate_normals(torch.tensor(positions), quats).cpu().numpy()
            map_to_tensors["nx"] = normals[:, 0]
            map_to_tensors["ny"] = normals[:, 1]
            map_to_tensors["nz"] = normals[:, 2]
        elif normal_method == "model" and ("normals" in model_state or "gaussian_params.normals" in model_state):
            CONSOLE.print("Using model's normal predictions...")
            if "normals" in model_state:
                model_normals = model_state["normals"].cpu().numpy()
            else:
                model_normals = model_state["gaussian_params.normals"].cpu().numpy()
            map_to_tensors["nx"] = model_normals[:, 0]
            map_to_tensors["ny"] = model_normals[:, 1]
            map_to_tensors["nz"] = model_normals[:, 2]
        else:
            # Default to zero normals if method not available
            CONSOLE.print("Using zero normals (method not available or specified as zero)")
            map_to_tensors["nx"] = np.zeros(n, dtype=np.float32)
            map_to_tensors["ny"] = np.zeros(n, dtype=np.float32)
            map_to_tensors["nz"] = np.zeros(n, dtype=np.float32)

        # Extract colors or SH coefficients
        if ply_color_mode == "rgb":
            # Try to find colors
            if "colors" in model_state:
                colors = torch.clamp(model_state["colors"].clone(), 0.0, 1.0).cpu().numpy()
            elif "gaussian_params.colors" in model_state:
                colors = torch.clamp(model_state["gaussian_params.colors"].clone(), 0.0, 1.0).cpu().numpy()
            else:
                # Calculate from SH if available
                CONSOLE.print("RGB colors not found, calculating from SH coefficients")
                if "shs_0" in model_state:
                    colors = torch.clamp(model_state["shs_0"][:, :3], 0.0, 1.0).cpu().numpy()
                elif "gaussian_params.shs_0" in model_state:
                    colors = torch.clamp(model_state["gaussian_params.shs_0"][:, :3], 0.0, 1.0).cpu().numpy()
                else:
                    # Fallback to white
                    colors = np.ones((n, 3), dtype=np.float32)

            colors = (colors * 255).astype(np.uint8)
            map_to_tensors["red"] = colors[:, 0]
            map_to_tensors["green"] = colors[:, 1]
            map_to_tensors["blue"] = colors[:, 2]

        elif ply_color_mode == "sh_coeffs":
            # Get SH coefficients
            if "shs_0" in model_state:
                shs_0 = model_state["shs_0"].contiguous().cpu().numpy()
            elif "gaussian_params.shs_0" in model_state:
                shs_0 = model_state["gaussian_params.shs_0"].contiguous().cpu().numpy()
            else:
                raise KeyError("Could not find SH coefficients in checkpoint")

            for i in range(shs_0.shape[1]):
                map_to_tensors[f"f_dc_{i}"] = shs_0[:, i]

            # Check for higher order SH coefficients
            sh_rest_key = None
            if "shs_rest" in model_state:
                sh_rest_key = "shs_rest"
            elif "gaussian_params.shs_rest" in model_state:
                sh_rest_key = "gaussian_params.shs_rest"

            if sh_rest_key:
                shs_rest = model_state[sh_rest_key].transpose(1, 2).contiguous().cpu().numpy()
                shs_rest = shs_rest.reshape((n, -1))
                for i in range(shs_rest.shape[-1]):
                    map_to_tensors[f"f_rest_{i}"] = shs_rest[:, i]

        # Extract opacity
        if "opacities" in model_state:
            map_to_tensors["opacity"] = model_state["opacities"].data.cpu().numpy().squeeze()
        elif "gaussian_params.opacities" in model_state:
            map_to_tensors["opacity"] = model_state["gaussian_params.opacities"].data.cpu().numpy().squeeze()
        else:
            raise KeyError("Could not find opacities in checkpoint")

        # Extract scales
        if "scales" in model_state:
            scales = model_state["scales"].data.cpu().numpy()
        elif "gaussian_params.scales" in model_state:
            scales = model_state["gaussian_params.scales"].data.cpu().numpy()
        else:
            raise KeyError("Could not find scales in checkpoint")

        for i in range(3):
            map_to_tensors[f"scale_{i}"] = scales[:, i]

        # Extract quaternions
        quats = quats.data.cpu().numpy()
        for i in range(4):
            map_to_tensors[f"rot_{i}"] = quats[:, i]

        # Handle oriented bounding box filtering
        if obb_center is not None and obb_rotation is not None and obb_scale is not None and HAS_NERFSTUDIO:
            crop_obb = OrientedBox.from_params(obb_center, obb_rotation, obb_scale)
            assert crop_obb is not None
            mask = crop_obb.within(torch.from_numpy(positions)).numpy()
            for k, t in map_to_tensors.items():
                map_to_tensors[k] = map_to_tensors[k][mask]

            n = map_to_tensors["x"].shape[0]
            count = n

    except KeyError as e:
        CONSOLE.print(f"Error loading checkpoint: {e}")
        raise

    # Filter out NaN/Inf values
    select = np.ones(n, dtype=bool)
    for k, t in map_to_tensors.items():
        t_array = np.asarray(t)
        n_before = np.sum(select)
        if t_array.ndim == 1:
            select = np.logical_and(select, np.isfinite(t_array))
        else:
            select = np.logical_and(select, np.isfinite(t_array).all(axis=-1))
        n_after = np.sum(select)
        if n_after < n_before:
            CONSOLE.print(f"{n_before - n_after} NaN/Inf elements in {k}")
    nan_count = n - np.sum(select)

    # Filter out low opacity gaussians
    low_opacity_threshold = -5.5373  # logit(1/255)
    low_opacity_gaussians = map_to_tensors["opacity"] < low_opacity_threshold
    lowopa_count = np.sum(low_opacity_gaussians)
    select[low_opacity_gaussians] = 0

    if np.sum(select) < n:
        CONSOLE.print(
            f"{nan_count} Gaussians have NaN/Inf and {lowopa_count} have low opacity, only export {np.sum(select)}/{n}"
        )
        for k, t in map_to_tensors.items():
            map_to_tensors[k] = map_to_tensors[k][select]
        count = np.sum(select)

    # Write to PLY file
    filename = output_dir / output_filename
    write_ply(str(filename), count, map_to_tensors)
    CONSOLE.print(f"Successfully exported to {filename}")

    return filename


def export_matrix3d(input_path, output_dir, output_filename="splat.ply"):
    """Main export function for Matrix3D models"""
    input_path = Path(input_path)
    output_dir = Path(output_dir)

    # Check if input is a checkpoint file
    if input_path.is_file() and input_path.suffix in [".pt", ".pth"]:
        return export_matrix3d_checkpoint(
            input_path, 
            output_dir, 
            output_filename,
            normal_method="calculate"
        )

    # Check if input is a directory containing checkpoints
    if input_path.is_dir():
        checkpoint_files = list(input_path.glob("*.pt")) + list(input_path.glob("*.pth"))
        if checkpoint_files:
            # Use the most recent checkpoint by default
            checkpoint_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            return export_matrix3d_checkpoint(
                checkpoint_files[0], 
                output_dir, 
                output_filename,
                normal_method="calculate"
            )

    # If we get here, we couldn't find a checkpoint to export
    CONSOLE.print(f"Could not find checkpoint file in {input_path}")
    return None


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Export Matrix3D model from checkpoint")
    parser.add_argument("--input", required=True, help="Path to checkpoint file or directory")
    parser.add_argument("--output-dir", default="export_output", help="Output directory")
    parser.add_argument("--output-filename", default="splat.ply", help="Output filename")
    parser.add_argument("--normal-method", default="calculate", choices=["calculate", "zero", "model"], 
                        help="Method to generate normals")
    parser.add_argument("--ply-color-mode", default="sh_coeffs", choices=["sh_coeffs", "rgb"], 
                        help="Color mode for export")

    args = parser.parse_args()

    result = export_matrix3d(
        args.input, 
        args.output_dir, 
        args.output_filename
    )

    if result:
        print(f"Export successful! Output saved to {result}")
    else:
        print("Export failed.")
        sys.exit(1)
